{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9057497",
   "metadata": {},
   "source": [
    "## Deep Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "100ad090",
   "metadata": {},
   "source": [
    "**1) Περιγράψτε (i) πώς διαχωρίσατε το dataset για τα πειράματα σε training/validation/test sets και\n",
    "(ii) το parameter setting του NeuMF που χρησιμοποιήσατε\n",
    "(0,5 μονάδα)**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e6be6c4",
   "metadata": {},
   "source": [
    "**(i) Dataset Splitting Methodology**\n",
    "\n",
    "The experiment was conducted using the **MovieLens 100K (ml-100k)** dataset. The raw data, contained in the `u.data` file, consists of 100,000 ratings from 943 users for 1682 movies. To prepare this data for the NeuMF model, a custom Python script (`prepare_ml100k.py`) was implemented to automate the data splitting process, strictly adhering to the methodology described in the NCF paper.\n",
    "\n",
    "The splitting process followed the **leave-one-out evaluation** protocol, which was implemented in these specific steps:\n",
    "\n",
    "1.  **Data Loading and ID Conversion**: The `u.data` file, which is tab-separated and has no header, was loaded into a pandas DataFrame. A critical preprocessing step was performed: since the original user and item IDs in the file are 1-based (starting from 1), they were converted to be **0-based** (starting from 0) by subtracting 1 from each ID. This is necessary for the model's embedding layers, which expect zero-indexed inputs.\n",
    "\n",
    "2.  **Training/Test Split**: For each user, all their interactions were sorted chronologically using the provided timestamp. The single most recent interaction for every user was identified and designated as the **test sample**. All other, older interactions for that user were consequently placed into the **training set**.\n",
    "\n",
    "3.  **Evaluation Set Generation**: The model's performance is evaluated by its ability to rank a list of items. To create a standardized test for this, the test set was augmented. For each user's single positive test item, **99 other items** that the user had *never* rated were randomly sampled from the entire item pool. These serve as the negative samples for evaluation.\n",
    "\n",
    "This procedure results in a test environment where, for each of the 943 users, the model must rank a list of 100 items (1 item the user actually liked, and 99 they did not interact with). The final output of this process consists of three files used by the program: `ml-100k.train.rating`, `ml-100k.test.rating`, and `ml-100k.test.negative`. No separate validation set was created; instead, performance was evaluated on the test set after each training epoch.\n",
    "\n",
    "**(ii) NeuMF Parameter Settings**\n",
    "\n",
    "The NeuMF model was configured and executed with a specific set of hyperparameters. These were set via a combination of command-line arguments and the script's default values. The exact configuration used was as follows:\n",
    "\n",
    "*   **Optimizer**: Adam\n",
    "*   **Learning Rate**: 0.001\n",
    "*   **Batch Size**: 256\n",
    "*   **Number of Epochs**: 20\n",
    "*   **Negative Samples (for training)**: 4 (For each positive interaction in a training batch, 4 negative items were dynamically sampled).\n",
    "*   **Predictive Factors (GMF Embedding Size)**: 8\n",
    "*   **MLP Layers**: `[64, 32, 16, 8]`. This defines a \"tower\" architecture for the MLP part, where the initial concatenated embedding is processed through layers of 64, 32, 16, and finally 8 neurons.\n",
    "*   **Regularization**: No regularization was applied (`reg_mf=0`, `reg_layers=[0,0,0,0]`).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5892997d",
   "metadata": {},
   "source": [
    "**2) Δείξτε πώς επηρεάζεται το HR@10, μεταβάλλοντας τα MLP layers από 1 έως 3 με βήμα 1 για\n",
    "NeuMF (i) με pretraining και (ii) χωρίς pretraining\n",
    "(1 Μονάδα)**"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
